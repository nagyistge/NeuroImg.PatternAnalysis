{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Week 3: representational similarity analysis (RSA)\n",
    "\n",
    "This week's tutorial is about RSA! We'll be looking at how to transform patterns into RDMs using various distance measures, how to test the relation between feature-RDMs and brain-RDMs, and take a look at exploratory RDM visualization using multidimensional-scaling (MDS).\n",
    "\n",
    "We will use data from the SharedStates dataset - a within-subject dataset used previously for a cross-decoding analysis (see [here](https://github.com/lukassnoek/SharedStates/blob/master/sharedstates_fullarticle_draft.pdf) for a draft of the corresponding article, which is currently in press). In the first couple of examples of this tutorial, we'll use the single-trial pattern estimates from the \"self-task\", in which subjects were shown short sentences about either emotional actions (\"action\" trials), emotional (\"interoceptive\") feelings (\"interoception\" trials), or emotional situations (\"situation\" trials). They were instructed to imagine as if they were experiencing/doing the actions/feelings/situations themselves (see figure below). <img src='self_task.png'>\n",
    "\n",
    "The self-task was done twice (i.e. in two runs). Each run contained 20 trials of each condition (action, interoception, situation), so in total (across runs) we have 120 trials (20 trials \\* 3 conditions \\* 2 runs). While we applied a (cross-)decoding analysis on this dataset for the original study, we will apply some RSA techniques on this data for this week's tutorial. (The SharedStates dataset is, by the way, also one of the data-sets that you can use for your final project (more info on Blackboard/Week 4)).\n",
    "\n",
    "In terms of skills, after this tutorial you are be able to:\n",
    "\n",
    "* Create representational dissimilarity matrices (RDMs) from brain patterns using various metrics;\n",
    "* Create custom \"conceptual\" feature-RDMs based on categorical conditions;\n",
    "* Statistically test the similarity between feature- and brain-RDMS;\n",
    "* Exploratively visualize brain-RDMs with [MDS](http://scikit-learn.org/stable/auto_examples/manifold/plot_mds.html);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Names\n",
    "student 1: fill in your name ...\n",
    "\n",
    "student 2: ... and the name of the person you're working with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading in and organizing data (yet again ...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_condition_names(design_file):\n",
    "    \n",
    "    contrasts = sum(1 if 'ContrastName' in line else 0\n",
    "                        for line in open(design_file))\n",
    "\n",
    "    n_lines = sum(1 for line in open(design_file))\n",
    "\n",
    "    df = pd.read_csv(design_file, delimiter='\\t', header=None,\n",
    "                     skipfooter=n_lines - contrasts, engine='python')\n",
    "\n",
    "    cope_labels = list(df[1].str.strip())  # remove spaces\n",
    "\n",
    "    # Here, numeric extensions of labels (e.g. 'positive_003') are removed\n",
    "    labels = []\n",
    "    for c in cope_labels:\n",
    "        parts = [x.strip() for x in c.split('_')]\n",
    "        if parts[-1].isdigit():\n",
    "            label = '_'.join(parts[:-1])\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            labels.append(c)\n",
    "\n",
    "    return labels\n",
    "    \n",
    "def generate_categorical_rdm(y):\n",
    "    rdm = np.vstack([y == y_tmp for y_tmp in y])\n",
    "    return rdm.astype(int) * -1\n",
    "\n",
    "def kendalltau_a(a, b):\n",
    "    \n",
    "    n = a.size\n",
    "    K = 0\n",
    "    for k in range(n - 1):\n",
    "        pairrel_a=np.sign(a[k]-a[k+1:n])\n",
    "        pairrel_b=np.sign(b[k]-b[k+1:n])\n",
    "        K += np.sum(pairrel_a * pairrel_b)\n",
    "    return K/(n*(n-1) / 2.0)\n",
    "\n",
    "def test_rdm(X, candidate_rdm, dist_func, corr_func, average=False, mask=None):\n",
    "    \n",
    "    if average:\n",
    "        X = (X[::2, :] + X[1::2, :]) / 2.0\n",
    "        candidate_rdm = candidate_rdm[::2, ::2]\n",
    "    \n",
    "    if mask is not None:\n",
    "        X = X[:, mask]\n",
    "    \n",
    "    brain_rdm = pairwise_distances(mvp.X, metric=dist_func)\n",
    "    brain_rdm = brain_rdm[np.triu_indices(brain_rdm.shape[0], k=1)]\n",
    "    candidate_rdm = candidate_rdm[np.triu_indices(brain_rdm.shape[0], k=1)]\n",
    "    score = corr_func(brain_rdm, candidate_rdm) \n",
    "    \n",
    "    if isinstance(score, (list, tuple)):\n",
    "        score = score[0]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "class Mvp():\n",
    "    \"\"\" Custom class to load, organize, and process multivoxel MRI patterns. \"\"\"\n",
    "    \n",
    "    def __init__(self, paths):\n",
    "        \n",
    "        self.paths = paths\n",
    "        \n",
    "    def load(self, voxel_dims=(91, 109, 91)):\n",
    "        \n",
    "        X = np.zeros((len(self.paths), np.prod(voxel_dims)))\n",
    "\n",
    "        # Start your loop here!\n",
    "        for i, path in enumerate(self.paths):\n",
    "    \n",
    "            X[i, :] = nib.load(path).get_data().ravel()\n",
    "        \n",
    "        self.X = X\n",
    "    \n",
    "    def standardize(self):\n",
    "        self.X = (self.X - self.X.mean(axis=0)) / self.X.std(axis=0)\n",
    "        self.X[np.isnan(self.X)] = 0\n",
    "        \n",
    "    def apply_mask(self, path_to_mask, threshold):\n",
    "        \n",
    "        mask = nib.load(path_to_mask).get_data()\n",
    "        mask_bool = mask > threshold\n",
    "        self.X = self.X[:, mask_bool.ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukas/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/lukas/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from skbold.utils import load_roi_mask, parse_roi_labels\n",
    "import os.path as op\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub007\n",
      "sub002\n",
      "sub003\n",
      "sub004\n",
      "sub005\n",
      "sub006\n",
      "sub007\n",
      "sub008\n",
      "sub009\n",
      "sub010\n",
      "sub011\n",
      "sub012\n",
      "sub013\n",
      "sub018\n",
      "sub020\n",
      "sub021\n",
      "sub022\n",
      "sub023\n",
      "sub024\n",
      "sub025\n"
     ]
    }
   ],
   "source": [
    "lud = {'Actie': 0,\n",
    "       'Interoception': 1,\n",
    "       'Situation': 2}\n",
    "mask_names = sorted(parse_roi_labels(atlas_type='HarvardOxford-Cortical', lateralized=True).keys())\n",
    "subs = sorted(glob('/media/lukas/data/PatternAnalysis/week_4/SharedStatesData/SELF/sub*'))\n",
    "\n",
    "scores = np.zeros((len(subs), len(mask_names)))\n",
    "\n",
    "for i, sub_path in enumerate(subs):\n",
    "    sub = op.basename(sub_path)\n",
    "    print(sub)\n",
    "    reg_dir = sub_path + '/%s-self1.feat/reg' % sub\n",
    "    path = sub_path + '/*.feat/stats/tstat*.nii.gz'\n",
    "    paths = sorted(glob(path), key=lambda x: int(op.basename(x).split('.')[0].split('tstat')[-1]))\n",
    "    labels = extract_condition_names(sub_path + '/%s-self1.feat/design.con' % sub)\n",
    "    labels.extend(labels)\n",
    "    labels = sorted(labels)\n",
    "    labels = np.array([lud[tmp] for tmp in labels])\n",
    "    cat_rdm = generate_categorical_rdm(labels)\n",
    "\n",
    "    masks = load_roi_mask('all', atlas_name='HarvardOxford-Cortical',\n",
    "                          lateralized=True, threshold=0, reg_dir=reg_dir, which_hemifield='left')\n",
    "\n",
    "    for ii, mask in enumerate(masks):\n",
    "        mvp = Mvp(paths)\n",
    "        mvp.load(voxel_dims=(80, 80, 37))\n",
    "        mvp.X = mvp.X[:,mask.ravel()]\n",
    "        mvp.X = (mvp.X[0::2, :] + mvp.X[1::2, :]) / 2.0\n",
    "        brain_rdm = pairwise_distances(mvp.X, metric='correlation')\n",
    "        brain_rdm_triu = brain_rdm[np.triu_indices(brain_rdm.shape[0], k=1)]\n",
    "        cat_rdm_tmp = cat_rdm[::2]\n",
    "        cat_rdm_triu = cat_rdm_tmp[np.triu_indices(brain_rdm.shape[0], k=1)]\n",
    "        scores[i, ii] = stats.spearmanr(brain_rdm_triu, cat_rdm_triu)[0]\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Left Parietal Operculum Cortex'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_names[scores.mean(axis=0).argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11582821, -0.13442059, -0.01340976,  0.01146322, -0.07725815,\n",
       "        0.15712431,  0.01684405, -0.03401773, -0.0085345 ,  0.20194157,\n",
       "        0.15010206, -0.07092855,  0.26829997,  0.20716204, -0.03940524,\n",
       "       -0.01251444, -0.0116169 , -0.02123825, -0.0269398 , -0.05358783])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[:, 30]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
